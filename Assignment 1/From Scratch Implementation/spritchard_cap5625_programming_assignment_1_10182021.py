# -*- coding: utf-8 -*-
"""SPritchard_CAP5625_Programming_Assignment 1_10182021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/shaungt1/83c9e75f7062e34897957859165f3a0d/spritchard_cap5625_programming_assignment-1_10182021.ipynb

- **Programmer: Shaun Pritchard**
- **Date: 10-10-2021**
- **Assignment: 1**
- **Prof: Michael DeGiorgio**
<hr>

# **CAP 52625 COMPUTATIONAL FOUDNATIONS OF AI**

## Ridge Regression using Gradient Descent - Assignment 1
<hr>

*Note: I decided to use symbols to make it easier to view to the implementation of code in contrast to the mathmatical thoeroms learned in class.*

## **Deliverables**

>
*   **Deliverable 1:** build graph of dataset N=9 features tuning parameter effect on inferred Ridge regression
*   **Deliverable 2:** Illustrate the effect of the tuning parameter on the cross-validation error
*   **Deliverable 3:** Indicate the value of ùúÜthat generated the smallest CV(5)error
*   **Deliverable 4:** retrain  the  modelof ùëÅ=400 observations and provide the estimates of the ùëù=9 *best-fit* model parameters.
*   **Deliverable 5** Provide all your source code that you wrote from scratch to perform all analyses(aside from plotting scripts, which you do not need to turn in) in this assignment, along with instructions on how to compile and run your code.
*   **Deliverable 6**  Implement the assignment using statistical or machine learning libraries in a language of your choice.Compare the results with those obtained above, and
provide a discussion as to why you believe your results are different if you found them to be different.

> Note: 

***Deliverable 1-5 located here:***
https://colab.research.google.com/gist/shaungt1/83c9e75f7062e34897957859165f3a0d/spritchard_cap5625_programming_assignment-1_10182021.ipynb

***Deliverable 6 is located at:*** https://colab.research.google.com/drive/1W0aaP4C2_QJo4NTQ-mrODOepyaWxnQa-?usp=sharing

## **Import Dataset**
"""

# Commented out IPython magic to ensure Python compatibility.
#Math libs
from math import sqrt
from scipy import stats
# Data Science libs
import numpy as np
import pandas as pd
# Graphics libs
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# Mount Google Drive for data access
from google.colab import drive
drive.mount('/content/drive')

# Set up dataframe instance of dataset Credit_N400_p9.csv
df = pd.read_csv('/content/drive/MyDrive/Florida_Atlantic_University/Computational_Foundations_of_ AI/Credit_N400_p9.csv')
# Set up datafeme for testing
# df = pd.read_csv('/content/Credit_N400_p9.csv')

# Check feature (row:col) shape of dataframe
df.shape

# Build copy of dataset for Pre-proccessing
df1 = df.copy()
# Validate new dataframe
df1.head(3)

"""## **Preproccess Data**"""

# Assign dummy variables to catigorical feature attributes
df1 = df1.replace({'Male': 0, 'Female':1, 'No': 0, 'Yes': 1})

# Validate new trianing dataframe with dummy variables
df1.head(3)

# Separate independent n X 1 feature X  and convert to numpy array
X = np.array(df1.iloc[:,:-1], dtype='float64')
# Test print X feature data conversion results
print('Matrix shape:{X}\nValidate array:(row:col)'  .format(X = X.shape), '\n', X)

# Seperate dependant n X 1 feature Y and reshape to (400 x 1) vector numpy array
Y = np.array(df1.iloc[:,-1], dtype='float64').reshape([-1,1])
# Test print Y feature data conversion results
print('Dependant Feature:{Y}\n \nValidate array:(row:col)\n' .format(Y = Y.shape))
for i in Y:
    print(i, end = ' ')

"""## **Center response variables and standarize features**
- Convert dataframe objects to numpy arrays
- Center the response variable Y (subtracting the mean)
- Standardizing input features X to a Z score
<!-- - Dimension of Y is will be (num_samples,1) and dim of X is assumed to be (num_samples, num_features) -->
"""

# Center Y response variable(subtract the mean)
Y_p  = Y- np.mean(Y, axis=0)

# Validate Y response vairables - mean of y_
y_ = np.mean(Y, axis=0)
print('Mean of Y:', y_)
print('Matrix Shape:', Y_p.shape)

# Split centered (row:col) of Y feature
Y_row, Y_col = Y_p.shape
# validate feature split of Y
print('(Y_p) Row x Col:=',Y_row, Y_col)

# Standardized X feature n x 1 matrix  as X_p array and reshape
mean_X = np.mean(X, axis=0).reshape([1,-1])
# Center X
X_p = X - mean_X  
# Apply standard deviation to new shape[1,-1]
std_X  = np.std(X_p, axis=0).reshape([1,-1])  
# Caluate centered features divided by standard deviation
X_p = X_p / std_X

# Validate X_p feature
print('Matrix Shape:', X_p.shape, '\n', '\n', 'Mean of X:' , '\n', mean_X, '\n', '\n', 'Standard deviation of X:', '\n', std_X)

#Store and seperate (row:col) in variable for X_p training/test set
X_row , X_col = X.shape 
print('(X_p) Row x Col:=', X_row, X_col)

"""## **Assign local variables**"""

# Local Variables

# Tuning Parms
Œª  = np.array([1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4])

# Learning Rate
Œ± = 1e-5 # learning & convergence rate

# K-folds
k = 5

#Iterations
q = 1000 # itterations

#log base of lambda
Œª_log = np.log10(Œª) 

#Standerrdized X features
X_p = X_p

#Centered y features
Y_p = Y_p

"""## **Ridge Regression Batch Gradient Decent**

- Implement(inferred) Batch Gradient Descent for Ridge Regression on standardizing feature X_p and centered feature Y_p numpy arrays. Where p is n x p matrix.
- Œ± = the learning and convergence rate.
- Œª = L2 regularization tuning parameters.
- q = max number of iterations (1000) as specified.
- ùõΩx  = Ridge regression beta coefficients parms.
- MSE = is a storage list to contain the mean squared errors for each iteration of the Batch Gradient Descent algorithm.

*Note: I decided to use symbols to make it easier to view to the implementation of code in contrast to the mathmatical thoeroms learned in class.*

## **Ridge Regression Batch Gradient Decent Algorithm**
![image.png](data:image/png;base64,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)
"""

def RidgeRegression_BGD(X, Y, Œ±, Œª ) : 
    # Empty list to hold MSE errors
    MSE = []
    # Randomly initialize the parameter vector ùõΩ = [ùõΩ1, ùõΩ2, ‚Ä¶ , ùõΩùëù]
    ùõΩx = np.random.uniform(-1,1,(X_col,1)) 
    # Instantiate loop to update parameter vectors
    for i in range(q) : 
        # Store ùõΩx coefficients in temp variable
        ùõΩx_temp = ùõΩx
        # Update ùõΩx parameter vector as ùõΩx ‚âî ùõΩ ‚àí 2ùõº[ùúÜùõΩ ‚àí ùêóùëá(ùê≤ ‚àí ùêóùõΩ)]
        ùõΩx = ùõΩx - 2*Œ±*( Œª *ùõΩx -  np.dot( X.T, Y - np.dot(X,ùõΩx) ) )
        # Calcualte vector direction of response variables
        ≈∑ = np.dot(X,ùõΩx)
        # Instantiate temp var "MSE_temp"square-root of real Y variables
        # minus the calculated ≈∑ response
        MSE_temp = np.mean(np.square(Y - ≈∑))
        # Append updated MSE_temp caluation to MSE list
        MSE.append(MSE_temp)
        # Caluate the divided absolute values of ùõΩx coefficients minus ùõΩx
        ùõΩt = np.abs((ùõΩx - ùõΩx_temp)/ùõΩx_temp)
        # Calualte the max value of ùõΩt and store in ùõΩm
        ùõΩm = np.max(ùõΩt)
# Console log to test my code:
#-------------- Feature Testing Output----------------------------------- 
        if (ùõΩm < Œ±):
            print("Testing:\nBatch Gradient Descent(RR_BGD) breaks on: {i} iteration".format(i=i))
            break      
        # Test for convergance error 
    if (MSE[-1] < MSE[0]): #Check MSE is lower than the initial value
        pass 
    else :
        print("Testing:\n Error not converging with lambda = {Œª}param".format(Œª=Œª))
    # Output updated coefficients and MSE
    return ùõΩx, MSE

# Test tunning paremters inferred on RidgeRegression_BGD()
# Create emtpy list to store updated coefficients
ùõΩ_lst = []
# Create counter for test ouput
count = 0
# Itterate through RidgeRegression_BGD oupt: ùõΩx, MSE    
for i, l in enumerate(Œª):
    # counter
    count += 1 
    # print('Tuning parameters {} \n', lmbdas)
    print('Tuning parameter converged at = #{c}Œª {} \n'.format(l, c=count))
    # run RidgeRegression_BGD
    ùõΩx, MSE = RidgeRegression_BGD(X_p, Y_p, Œ±, l)
    # Append ùõΩx beta coefficients to empty list
    ùõΩ_lst.append(ùõΩx)

"""## **Deliverable 1:**
> Build graph of dataset N=9 features tuning parameter effect on inferred Ridge regression
"""

# Output Deviverable 1: inferred tuning parmeters of ridge regresion
sns.set_theme()
sns.set_style("darkgrid", {"grid.color": ".5","image.cmap": "mako", "grid.linestyle": ":" })
plt.figure()
plt.figure(figsize=(16, 10), dpi=70)
plt.xlabel('Œª Tuning Params')
plt.ylabel('p=9 features')
plt.title('Deliverable 1: Inferred Ridge Regression Coefficients')
for i in range(X_col) :
    ùõΩj = [ ùõΩx[i,0] for ùõΩx in ùõΩ_lst  ]
    legend = 'Beta_Œª_{}'.format(i)
    sns.lineplot(x=Œª_log,  y=ùõΩj , label=legend, )
# Output Deliverable1.jpg to file
plt.savefig('SPritchard_CAP5625_Assignment1_Deliverable1.jpg')
plt.show()

"""## **(5)K-Fold Grid Search Cross Validation Algorithm**
- (5)K-fold Grid Cross Validation calualted Batch Gradient Decent Ridge Regression with hyperparameter tuning
- Use grid search CV to trian and test 5 k folds
- Calculate test and trainging errors
- Test MSE on tuning params
"""

# Implement start and end of test k-fold data split
X_row = X.shape[0]
# Divide absolute row features by k = 5
X_row_test = X_row // k
# Store data in k-fold array (Kfold/Kfold_ )
Kfold = [ X_row_test * ind for ind in range(k)] # initial k-folds 
Kfold_ = [ ind + X_row_test for ind in Kfold ]  # End k-folds

# Grid Cross Validation for Batch Gradient Decent Ridge Regression with hyperparameter tuning
# Instantiate empty list to hold Cross vlaidations errors
CV = [] 
# Add a counter to iterate tuning params and errors
for i, l in enumerate(Œª) :
    # print('(5)K-fold CV tuning parameter error = {}'.format(l))
    MSE = [] 
    # Loop through K trianing and test vectors
    for i in range(k):
        #Hold-out 5 k-folds arrays (80 x 9)
        CV_fold = Kfold[i]
        CV_fold_ = Kfold_[i]
        # Seperate training feature variables
        X_train = np.row_stack(( X[0:CV_fold,:] , X[CV_fold_:, :] ))
        Y_train = np.row_stack(( Y[0:CV_fold,:] , Y[CV_fold_:, :] ))
        # Seperate testing feature variables
        X_test   = X[CV_fold:CV_fold_, :]
        Y_test   = Y[CV_fold:CV_fold_, :]
        # Standardize X test set
        X_test_ = (X_test - np.mean(X_test, axis=0))/np.std(X_test, axis=0) 
        # Center Y test set
        Y_test_ =  Y_test - np.mean(Y_test, axis=0)
        # Implement ridge regressionand MSE on test data
        ùõΩx, _ = RidgeRegression_BGD(X_p, Y_p, Œ±, l)
        # Product transofrmation of test data on trining set
        ≈∑ = np.dot(X_test_, ùõΩx) 
        # Claulate average squareroot of Y(test)- ≈∑ variables
        err = np.mean(np.square(Y_test_ - ≈∑))
        # Append calualtion to MSE list
        MSE.append(err)
    #Caluate average of updated MSE    
    CV_err = np.mean(MSE)
    # Append averaged MSE variables to CV list
    CV.append(CV_err)

# console log  to test CV code
#-------------- Feature Testing -----------------------------------
print('Initial (5)K-folds', Kfold, '\n')
print('Ending  (5)K-folds', Kfold_, '\n')
print(X_test.shape, Y_test.shape, X_train.shape, Y_train.shape, '\n')
print(X_test[0,0], Y_test[0,0], X_train[0,0], Y_train[0,0], '\n')  
print("Mean Square Error",err, '\n')
print("MSE value",MSE, '\n')
print("CV_error", CV_err, '\n')

"""## **Deliverable 2**
- Illustrate the effect of the tuning parameter on the cross validation error by generating a plot.
- Grid Cross Validation tuning errors for each tuning parameter value, perform five-fold cross validation and choose the value of ùúÜ that gives the smallest value.

![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQgAAABnCAYAAAD8I9zEAAAgAElEQVR4Ae2dB3hUxdfGyaZ3AoFUkgABDL13ASlSFaTYQEQ+qoA06R0bKiJYQBFUCEj7UxUpgpRAICA1kFADpPdett7f92waCdmEZLNLsnDzPPPs5u6dmTPvmfvemTNnzlRB/BMREBEQESgGgSrFXBcviwiICIgIIBKE2AlEBEQEikVAJIhioRF/EBEQERAJQuwDIgIiAsUiIBJEsdCIP4gIiAiIBCH2AREBEYFiERAJolhoxB80IZAadZ+gGzcIDAzMT9cvHmPN3Jms+DOINLmmXOI1Q0VAJAhD1VyFyC3nwIwO1LS1wMzUFNMCydjMk/HbLpGqqBDBxEr1hIBIEHoC9vksVs6+qW3x9HqJLn1fY9CgQY/T4IlsvPCALNXz2fIXtVUiQbyomteq3XL2TetI54EzOHwrkoSkJJLyUwpZCiWCVuWKmSorAiJBVFbNVEq51ATRiS5D53ImMgOVyAaVUku6FEokCF2i+dyXlTuCGDSDw8HhxMbGEhMbR1JKOnKlOLd4HtUvEsTzqFW9tUnOwTldeKlhawYMHcprfbrTqVMXBo2cyo+7/YhJk4pTDL1hXzEFiwRRMbgbaK0C4f8dYMO6n9i8bQe7dm1n/VezebWpOzXrdGTBrquky8V5h4EqV6PYIkFohEW8WBwCgqBCqVCiEgQEQUCZlcDxjdNp4miDU78viEzMLC6reN0AERAJwgCVVnEi55BC4TGCivunN9HXxw7zJhMIj0mtOPHEmnWOgEgQOof0+S1QFXONfTt3ceFuIor8JQwFwcfW0qOuPTX7fi6OIJ4z9YsE8ZwpVJ/NkfmvoJWnO/2m/ERgVBqCALLke2yYMxCvWk2Z/Ns5UmXiaoY+dfCsyxYJ4lkjbsD1KYK3Mqxtbao5ONGwdVdeGziArq18qNe4E1PX7OdRUpa4imHA+tUkukgQmlAxsGuCSkFmerr+PRlVKuRZ6UTcucKJQ/vZvm0HB/45R0h0KjLRD8LAek3pxBUJonQ4Vdq75OnRXDy0mUXTFrH9ehjSwhZE/cgtCKhUqtwkiKMG/aBcKUoVCaJSqEELIQQp4ZcPsuKjN2nt7YSVbSs+ORVM5rMgCC3EFbMYJgIiQRig3qSJD9j99SQ6NHDF2swYI6MqGFm35gu/WyJBGKA+K7PIIkFUZu1okC3myk4mvtaWl5p3Y9yilSwf0xlHSxMktm34yu82WeIIQgNq4iVtERAJQlvkKiSfiqDdy5m5cDXHroWSKVMS7vcJrapbYWLbViSICtHJ812pSBAGpl+lLJXUdFm2q7Na9KiAFbQtM0EoSU+K5dGDEO7fv18BKYTQ6ERkCtFnorJ3P5EgKruGniKfVgShSuDId9No37AuXl5eFZDq0Hn019yIyHhK68SfKxoBkSAqWgPlrF8rghDSubhpLs2crTGqUoUquclIYoGTV318fBrSsKGOko8P3l7u1HSwwURilFuXhNoD5nPpUXo5Wy9m1zcCIkHoG2E9l68VQQCqlDv8Pr0vTlYm+SRhZOzI64t3cTs2DalMhkxHKS0hjHN71vBWey8sjNUkIRKEnruFzooXCUJnUFZMQdoSBAhkhvuzZFBDbM0kuW92I6zd2rJ420WSZEqdNkhQZRLy9zLaOVtjLBKETrHVZ2EiQegT3WdQtvYEoRZOSdS1HbzVvCZmucN/I4kpXp1Hsvu/yAI7NnXTEEEeweoh3tiaGYtTDN1AqvdSRILQO8T6raB8BAGCIo2zvnNo5WaLxCjHHmFk6kDXCWu4GZOpYzdqgeCNI/GwsxAJQr/dQmeliwShMygrpqDyEoRaaln8bTZ8PBAXW7P8qYZJVR/G/nCU2CyFTkki5sr3dHW1x1s0UlZMhyljrSJBlBGwyna7LghCPdVIuneMj/v6YGXyeKXB2qMrK/6+S4Zcd/4K6XEXWPnRKKZ88QchcVmVDU5RnicQEAniCUAM7V/dEAQgyEm4spH+datiKsld+jQyxr3t++wPSkRXHCGo5KQlJZCUmoEyPyqVoaH+4sgrEoSB6zrS/3PaqD0pbVrz5ely7sUQFARum0ZzZxuM8+wRZnZ0H/89gTHiQTkG3lW0El8kCK1gqyyZVNzaPpF6VS2QmNdnxr6rpJdzdVKWFsrvcwfiWdU81z/CCEuXJkxde5S4DPFk3sqi+Wclh0gQzwppHdWjUmQSeusq50//w55N3zDq5dpYmUioYmSJd68xrN60jxP+/3HjfmT2Zq4yVysoib9znNmDWmJrmusfYWRCjSYD+cXvAdJyElCZ5REzVCgCIkFUKPxlrzw97hpzX2+Kl7szjg42mOa7L1fByNgcO4cauLjWwuf1OVwNSSh7BeocKimhp9bSq34NjPNcsSUW1Oo+B/+odJTilnLtcDXAXCJBGJrSBHVcyEwyMzLIKCFlSmWoyrH4IKjS+O/nsdSvbpHvH1FFYsXLU//gXmIW5Sja0BB/oeXVKUEoMpIID7nDzcBrXLt2nRvBt3kQFk1Kplyna+kvtMaeYeNVWY/YMrMPtWxN8/drWFZvyPRfThKdrlv/iGfYrKJVCert7zGE3A7i+rVrXL9xk9v3HhAVn4r8BV9p0QlByFIjObPnJ2aNG06/nl3p2L4tbdu0pUOnl+nZ53XeHTOL349dJ1Uhw/+3RUyfMokPP/wwP02esYxdZ2+RWWDsKntwhpVLZuXfk3P/JJb6BpAqFY1lRXu5Pq4IpD48y4IhLbA3M85xojIyxa3VUH49eYcsvT88mfj9uoQZHz3uLx/NXMje/6KQFegrRVuuIDRgH5/Mnfq4/0yaw69+98lUFJ4fSRPucuCXz5k4YjA9u3aiXbs2tOvQkS7dejJg8DtMnv8tZx6kkRO6QsGFrZ8yc+pjeQr2Y03fZy3fzM3kTAzVdFNugpAm32XttNdo4FId52YDWLJ+L+cuX+XcPztY8GYbqpobIzF14c3PdxGVpSDUfwtje9bH1swEiUSCpYM3E9Yc5F5cGgX7myotHL9dK+nnUw0LE2MkxlZ4vzqZ7QHhT+kcRbuLeEV7BNR+C/dPbmRQC+f87dpGJjY0fWs5l8NT9TwyVBJ7+1+WvtcBRytTjCUSTKwcGbJ4N5EZxY9KhaxQfOcNwdXaNLuPGVu70H3Uck7fi8990HPwUMUFsHRYOzzda/PKu7PZetif69cvc8j3Swa3r4uliQRbl9asORVNVvY7SSDh/hlWjOmGs7UZxhITvNq/wfujxzJu3LjsNHbsaIb17YynozXGxhJq+IzmcEQKhvpKKxdBqDLD2TS5MzVsbKjdfRJHgqOzz0dQn7gkCEoUmff5cUQz7C2cGfLJdiIzlaCSEfzPWnrVs8+e21av/z6Ho9J4gtjVnjuoVHLOf9GXalbmVG0+ggOBES/8kE/7R137nII8geM/TsGnplX+VENi7sIbX/xFlL6nGkIWlw98QQdXG8zNTDCSmOHz6hSO3U8p9EJ53DqBpKAjjOvujYWpBKMqRji1GMQW/yc2n8nD2TqlOzVsbGn39nLOh6Xkb05T97uI0+vp3bAmdk7NWHUijyDU3VLGjcPf8Upt9d4VE/p8cpro5Czkcnl+kqVHc3T1ROo7WuDYYBSHwl9EghDSuLJxPPXsLbHz6syKPVdIL/KUC8Rc/oX+DZsw8qvdRGXlmLZkkRdZNKw1VsZGOHi9we6QVA0EoVa5gpOLu1KtqjtDl24nIs1Qefhx9zXUb8rEIH6e3IualnnxI4wwdWzNwp1XSJQq9TiSUHBLffantzNturfHxcYS29qdWbk/sNCUNB9XZSYB2xbS2tuHVi85YmlmQu2XR/HnzeRCqy9pV7fyWhMXLGydGf/jWZKzCk8CBHkk26b1psFLnfnhdEyB5d2cw4r7+9hjbGRC38/9ScgonFctiyziFDP6NqN+qwn8E/kCEoQ89BjjOtfGzMSSVkOXcCEyQ2MnkWfGEXDkIGdvPnqsUEUc+z8djruNCZbVffj04EOkRchFvRv5Pp/19sDZpwc/HLmNtOAcJL9HiF+eDQIC6Y9OMa9ffazz/COqSHBuMZTfz4aSVaJNoDwSKrh9/Cd61XOi97wvGd7cGSsrZwYv/oOw1KIvDFlqGN+P7UiDbqOZPbgpDpYm1Ok6moPBBUccKu7t/4xWHjaY2bky7berpBU5U1RFQvAZ/jxwhFsxWQXIRUXIGV8GNCqZIBDSueN/mAMHzxOZKTfYVR8tpxgKgnYuorGzJcZWjoz48ihJJXjQCIL62PiCnURJ+N9f0sLDFmPL6rz1yV/EazA8ygPX0dm1Oi0HzsU/Ir2YIWXBcsXvekVAUBJxaQuDG1fP36+htke0e2cp50ML25B0J0ceQVSj26K/2T3vVWramOPafRrn7icVeSnF39rKQJ8GDFn4I6v/rz3VLDQTxN29n9KyljUScwcGLdhJRIasSFnqTpvddws1Rk0QW55OEOo8ufkLZTewf7QjCGUUOxYNw9nSGItqdVh64BFZmkYAJYChjDrG6DaemEosaP3mci7FPXHwq5DF2c9fo6ajM+99eYSEJ4aAJRT9DH9SIU1PJSUlReuUlqmOUP0MRS5nVYI8lVMbZ2Tv18iLH2FiV5fRX+8jKl1eztI1Zc8jCAc6zjlEkP86ennaY+bQms//CSKzkEOGnDMrXse7SQ++3X+aTRM64GCuiSAg8/p2BrZwxdjIGKemA/jpyE3SShVFq2SCkKaFsXvtav7nd4O05yBqt1YEoUq+wVejXsY228rbkV/+02K3nzKG7RM7YWdmjHOrYey8GFNgGAeqxABm9axPDa9ubAiIpVS609S/9HlNGca2pZP4YOQIRozQLk1bfZQ4A/MTyYoJYt20/jjZmOYHobXz7sU3B28WWUYsP/yPCaL9x38SGnqbz99sjI25De1m7CQy7TEpqRLPMrmjF+3emINfSAibx3WgajEEgTyKvz57F++q5hgbW+Deoj+Lf97HtYcJyEpk7JIIQslDv2/p4dOc8WsOEFMpO23ZNKIVQSgjApj7RjPMJUZUrdWfHXdTijEyliSMisg9U6ljb46ZU0uWbb9Aev48VkXEsW/p4OWAz7DvuJUkLTr8K6noZ/Wb4g5fv/MyzRv54OOjXerx0RbC0zQMb59VG7SpR1CScOsw03rWxzI7CG0VqhiZ4zH4G+4nPTES1Kb8QnnyCKIqrafvIyoxiWPrxlO/qgWW9Udw8EES8uwRmIL7O6bS2MOT//vmGLHp4fw+pj32xRFEdqCcIDYvGU5jZ2tMjI2xcPCgQ//3+dL3KA8SMp+YFucJVZAgjKnXawxzFy5h2bKlLFkwg2Ev18POrg4frNr/4hKE4uEZpvX3yd4H4OAxmL2PiluFyANV86eQeJC31PEHTGswaMk2IvKswcpY9n0yHDc7dz7ceY+0nB6guZAKvSojMTKUhw8e8EDLFBaTmr+8VqFNKWvlgozYgLX09LLDJHdruFm7WdyIS9exQe4xQbSc8j+iUmWEnvuDwc1rYGxak7Gbg0mRqiArmG+GtcLdewBbrsciU4Sz8YN22JtpnmLkNFdAlhrN+b3fMqRtbSxMjDCSmGBT3ZNuI5fhF5JQaFSbk6cgQUhwatSZ3n37M2DAAPp2b4u7nTnGFp6MEgmiYTZBVPUYVMIy5VN6nZDCbyMbYGtmSt3XF3EtPOecBFnYeea+0ZyqDcfwb2SaBiXllKuUZZAYF01covqe0k/k5VlpxMXEkJQuNYj5/549e6hRowbW1tZlTvXq1SM+Pv4pitDyZ1UGx5a+Sg21Q5J5Tfos/TN7S3jpNVGaeh8TRLNJO4hKVaCMu8YX73fG1tQY78GrCE5IJ/bsT3Rv4EyrcZt5lCJFUIXxy/ttsCuRIHLqF5QKMqKD2PnlONrWdcLKzBiJiRkuHcaz/2bsE6tnBQnChN7LTxKZmIFUKkWalclV3w9p6PYSo0siCJWU+PD7BF4NJDRBVmz/Lg06+r5HqymGKiKAeYObZ08x7Nx6sDkwWcuIQwK3to6ljq0Z5rUHsONKGApBwb0Tv9DHpxbdFhwgTu1c9eSfoCDx4RV2freYieMn8M22syTkzvfk6SkkJsRnPxTqByM7xYRy1d+PSw+TkKtUxASf4us5E/lw9lfsPXObZJmqck5hctu9a9eubGLIO+CmLJ/u7u56IgglCYE7ea+VMxYW9rQYtgj/h4l6INwCBPHh9myCQJXC6bVTqF/dHDv3bvx8+io7lr+Hp2srPv3nERlqg3kZCCIHZgGlQkbY5QMsGPEK7up4GMZmNB78GRciCu5gLUwQT/pBpMUEsHzsaL7c4UdiMUZKVfx1vhrzCo72Piw4HEoBM8qTPb3C/9eKIIQCRkrrmk1ZdTJOayNiwp3dDKpvh6m5JxO2XiEtI5lDq0ZSx/sVvj91jyLL06iIv3uaT8YMZsDYZezxu0l8vtutkoANH/Pe20MZMmRIfho8sA+tG7Xnox3XUPtaCUopsfcvs2vlh/TuOYSVuy+SWIkNSurzMzds2MBPP/1U5uTr60tWlu5jP2aFn2P5W22xMzfDrcVgfvn3NhnFPBDl6+UaCAKB1Ot/MKiJC+bWNRk8YSEjezakbv/PuBabkTPFKTNB5NKESkHCvZMsersD9mYSrBwb8+mBu2Tmx9wrmSBUShkxoQ+Jyh7Vam55ZthlVk1/m659p3FI/dLS7ZBLc6VaXtWKIFBEsm3+EJwsjDG1c2f65kCtA5tKkx6wYpgPlqbmNBjjy6Ow2ywb9BKN3ljE5bCiR7Mp0qP4bWZ/OgyZxfHg2Cfm73L2TmmBvYUxRkZGhZNJXaYduP444pIgoMiM5+iXQ2nXfQTbz4U+UVYpEFXc47vRvems3pzWVrv0+pwdRDzFSJnjR5K7Jp+3Nl+Gz1K0pEy3CJnh/O+T9/C0N8fc3ospP/sRm6Gv3Z2aCEJtYXzEz++3xd7cFPtqTlSrXo9xm86RLMt92rQkiGwgVFKubJlPY2crjK1rMvqbf0nL2YyhDpZRej+IYlBVKaQkxUUTEZVAlrLQOm0xOSrusnYEgZzrW+fiU9MCI7Oq9J+1lfD8t3jhxsgzYvl3x2YOXbitwRVb7dqezMGVw3G3MsW0/mh2HVvFK3V9+GDlPmKK+D4IhJ3+ki5NOjB/kx8pRd5YcvZMaUu7vhPZcfYawbducSsv3Q4hPkNWxICWGnmeyd2bMHDurzxMfrxkVrgVxfynCGZ5v8Z4ubng4qJdaj16I6HqOXMxVVS2y4Iqi2t/rqR7PQdMTK3pOOE37ibpMz5EMQSBioi9M3PjVUiwbzGSQzeiHuu3JIIQZDy6fJzfNu7lZoKmnZYCcSe+p6N3NYytajBq5bGyE4SQxr9fjqBbjzHsv5s3SpASdvMCp08c5/jxUwSGJxfaPFbZdK2WR0uCAGnIIUa198BUYkrdbuM4GBSvwdgiEHFevbGlHu98vjNns9aTKAhygo6soZuXLRLTuvR/ox0ezfqx/vi9ohuzVHH8OqoFTV4Zxf5ATfWpCaIdLw+dj39UTtTkQm/fJ+vODp6UwO5Ph9KgzXD234gs47ZcKTEPbhMUdJObN7VLd8PUPiQGQw/Zy5uTe9XH2tyaOq9+zL8h2tqfNChD4yX1Xox19PS2p+nEbTk2iNz7VEl+fNjGBUuL6vSe+QshSbLHJahCWf9eG+xMTajTZTQHgwq4WgspHF8zkfpODZi+9zapeaOO/NxKHh38kjaedphX9WLO1kAy8ue6KkL8NtO/Ycmu1orYM8zo8RKudYaxJ28pVkji9KZP6dfUGRv7Rszcc4XUMjoY5ov4jL5oTRBqQ9GF9WOpqx5mOtTl/RV7iH7C2iJk3mfdB61xsHR5vJuzSMMEUm8fY3yPuphKTLCwsqPV0MUEaNjboYrax5AGbrzywTfc1OgbkUcQCzgXVcpToQQpV/Z/TvvajZiy86rGUU4RkQteKMNQvxBZ5ecrWFjl/i6kBfHd/3XCycocx6YDWX/yrh73YORiIcgIPLSKLh521Bu5gfCCozwhi3O/L2HytEXs8CscTwTFHVYOaY6NiYRaHd5l79XExy8wIYVj346jTlULGg7+gv8iCxohQciKYs8nw/GwM8Ox6XD2BSUUMMIruHX8J3p622Xv5nzSSJkttTKNy38sopWbHTUajOJwRHK+n1BmfAjLBtXDrnZvfj8fQgFKq5TK154g1HupMiLYuaAvbtbmWNdsyDuLfuVKRCpKpZz4+/6smdQbNzv1nvyaJRAECBn3WDvpVRzMJNlzvg++Palxb0f6Pwuo5+LCkMV7icufExbENWeK0bzzIOZ8spw50yczaepsVvse4l5sejGOLwKh/tsZ2MSJTvP+JiGjcs8JC7ZW83e1NV6OQqlh9UdzhtJdVSVybMXbeFU1w7xGI6auU3uAFt0sVbrCSn+XIj2SrYsGU8vGDIs6A9l0IbwQKSmy0khOSSVLXqC9goKYi5sY2MQFkypVsHRtyfzfz5Cct18onyBMMbVxoe+ErzgZFJkdZ0Sa9JAD38+kk7cjZnY+TN9yqZCbvyIjmp2fvkNtO3XUb2MaD/qYr779jh9++CEnfb+aZTM/oJOPC+bGRtRsNYVTUan5I9O0mIt82MmVWt0m4XcnvtJPLctFEGo1y9Nj+eeXefRu3QBXF2dcXN3x8PTE3dWFmjVrUNOlFj4t+7Fs2xkS84dpT3QQIYsLv86imUc1XOv3ZfNVTa7bKu5tGImrkyuj15wmVeOqg5Iz375Dq8ZNaNelO6/26EKz+h44Vq2OT5+pHA0u7M6dI4VA/LW/eK9jLbze/ZnY1DLaIZ5oir7/VWYlERUWSmio5nTr4gEmvNab+b+fICnf8l4+qdR2hzt/fUXnOg6YmNnzyphVXI1+FudkpLFrTj9a+tTF09MTD8/aNG7Xh3X/hmve/ZvdTCWhF3czvl8rvGt74eHhgaenF94Nu7Job2CO052QRdDhnxnZuxW1a7ng7OSEi6sbnur7a7nj5u5Jky5v8s2Bq9nbwB9PAOX8tXQgrRt546WWx8MDr9p18fb2LpDqUrdO7fzfWw9ZwdX4jHyCiL+1kd6eTrQfvYqgGGn5FPMMcpebINQyqhQykqNDCPj3IDv+8GXz5i1s27Gbvw6f4FJwKIlpWchLtNYKZIRdZ/8OX7btP0+MxvMglVxbMxQXJzcmrDtf7MYapSydxIREMrKysp1Xkh5d5OvxPXC2rUaHmTtJSC/61ku+cZgPunjhNPAbYpIrt9Ii/llMW3dH7GxssNGQrC3NMavRlHmb/HSzWUhQEnPjb6b0bYK1qSmencaw50o00ny3eH32UgGlXJa9TKteqs1JUhRPqVtQKZFJ8+7P+5Rm98G8h12lvkeWQezDYM6fOMzenX/g67uF7bv2cyIgkMiEtEL357VSJZchzZclr+ziP6UyRQHfEIE72yZQ36ku73y2kwhNPj55FVWST50QRE5bBASVCpVSiVKd1N9VquztsqVqq6COIKXMzqP5fiU3f3grmyDGfn+2WIIoklc9h/17NV08rbFqM5PohIwnbhFIDPyb9zt74Dr4O2JTKvesMOzIPBo7WGNpY4djjRrZHpZqL8uCyalRT1btu6KTh1iWEsLP0/pmuxBb1OrOysO3SC1uJPgEsgbxr9oWlNtXs/utUoVKfU0vwks5MKMDNT1bscj3LOlFVuH0Umm5CtUhQZRLjlJkFojZMRE3Zxfe/vwQSRriR6BSkCWVPuHPoOL+qd/p08AWi7YfE6WBICIv7mFYSycajf+D+EoetSqbIKq702fqKvyuB3Pnzp2i6X4oCWm62DSl4NLGsTRyssbYui5jfzpJbKY+o0eVohsY8i2Kuyzr5Yl70z5s+PfhE/20cjbMgAgC5NfW0M7Nmb4fbeRBetEdkLJzX9H+pcbM2HCB5FwjpqBIxc93Ns2dHen48W4Sihwfp+DWP2vp7u3GoG/9SZbq592hK/XnEIQnQ5dvI1yfQ1RBQXzAj/Sq44C5uQMvj1tNUHQpV4Z01djnrZzMY4zycaJex3fZeSGMR/572eMfWmAJtfI12KAIgqzLfNzJk9avz+R0aNEIU/L/1tCpjhPebQayfN1W/vzrT7b/8gVv92hNx0HT+etGdP5yU74qFGn8u34iPnW68e2pu6g3Blbmv2dDEEqS7hxl+qsvYW1mTp0uH7DrwqOnxEmozKhVEtlkl5jTxQsXr2a8+cEERrw1iq/2XidZo8G9cshsWASBjLOrh9GoRR/WHrn1xC47EJLucvR/m1n9+RLmzpnNrFmzmD13Mas3/I+AW5Eao15Jk0L4ekRbWg5ZyH9h+g7jXn6lPwuCkMbfYv3M13GxM8PauQ3LdlwkQeOycvnb80KVIGRx8/B65k+dzKxla9jnf5sUvQb8LT+6BkYQkPrIj8k9mjFg1kYeFPScy8Yix+Akl2aQmpJMYmIiKanpyBTKYnwgIPT4Z3Rp1pEFatdtAzC+6ZsgBEU6/r5zaO1mh0TiwMDPDhGWUnQ6V/6u92KWIChlpKemkJYpRWkAHrQGRxCCMpPLe1fwartXmLPZj+hU7WI6qhRZxAftZUyXxgz86EduxBrG/DqHIGoxYNYP+J0/xYFdvqxft5YNvns4c/0e0Unp5XDdVhETuIt3WjhhYWbFS299w424zALLdLp4qNVLl9Lss0XVzk2V2+Kji/YadhkGRxBquJUZMZzZ/jUjBg9j0tJ1HL8W9jik/lP1IZARH8IR368Z++YgRs//iYuh6qhOT81YKW6IOf89/ZrWo0Hj5rRt35727dvTqqkP7jUcsKlWi5eHTWfryWCStTCmSCMDWD64MfaWVtTq8D67Lofr3O4gyDO4dugXFsyaw7p/7pFRuf3SKoXOK1IIgySI7FO35OmEBp5ht+8v7D0ZVIY1ZYGk0ED2bN3E3uOXiUqVPvbRr0hNlLJueVokAcf/Yv9fRzjtH8ClS5c473ecXeuX8VozVyzNrU9h2wIAAAc4SURBVPDuMort5x6U6eEW0u6zZfZruNmYU9WrA0u2+JNUZDdtKYUs4TZFWgwbJ3Wmmo0zw74/S1IlXzUqoSkvxE8GShC5ulE7VynlyORli0UgKJXZedQOMYb4p2nTl1KezoODC2jmaImJWQ1em+9LqIaDZTS2V5XK+d/n0sLVFlPLagycu5X7ibrwoyhaW0ZcELN71cLCzJ0PNl0kRRxBFAWpEl0xbIKoREBWBlEE+V2W9HDDysQY5+7TuBCS9HSxBAXhF7YzvKMnZiZm1Ok1m1OPHu8+fHoBZbsj7uav9Pa0x8S0PjMPXCXNQKZ2ZWvl83O3SBDPjy4BKdsnNMXeXIJZ43c4djPqqUbAzOgrrBjVCUdLc6o1HMzGcxF6ONsiF2QhnRNfDMLNxgyJZXM+ORFEhmEO4p6rXlNSY0SCKAkdg/tNzp7JLalqIcG8yXD+DYoumSCU8fz56VvUr26JlWtb5v+hDtlWYNu0DtuvzIzj0r6v6NOgGmbGVZBU78z3Z+8imiB0CLIeihIJQg+g6qtIVUYEV86d5drtcDI17Y5VJfHjsNrYmElwe/Vj/nuQUoIoCu7vnkcrVxtMJEZYOnrRrmtP+vbrRz8dp759XuXlts3wcrLDNPegHYl7b3wvPkA0QZSgokrwk0gQlUAJpRVBEbye7l4utOg3jWP3Cx9nr17ZyQrfw1DvapibO/HGIs2nX2fXpT4Z69oO3mpZ6/EhvEZGSCQSPSV1AOEqucf05XyaNBjKwesRj2NIlhYE8b5nioBIEM8U7vJVpri5jk7OtlhWr8fIpb9z9ZE6FJra8SidiFtn+WF8VxxtrPDuNpqd5x4Wu8wpjb3Bt+N7UN3CuNBDW5bzNsp3rxFWLd/nZFBMyVOg8sEl5tYBAiJB6ADEZ1WEMvwIUwe0xa2qFbY169Cp35uM/XAyE8e8x4AuzXBx9qTzkGlsOXFTY8i+HDkF4q7+xfuda2FhaoKJSUUkU5y6TeHcvUSRIJ5V59GyHpEgtASuQrIpM4mLeMiN/06xc+MaFn78EePH/B/jJk5l8dc/c/DsVR5GJyPTZJ8oILAiK5Wwe8EEBgZWWAoOiSRDTwbRAk0Vv5YTAZEgyglghWQXBJRKBXKZLOdMSKkMuaJgaLMKkUqs9DlEQCSI51Cp2jVJQKGOtyiV8ZQBiHbFi7kMEgGRIAxSbboXWki5yW+fzGLS1MUcCU4xmM1rukdCLLEgAiJBFETjBf6edW0rfRq5UKP2G+y6k3dUnC4BUZAUEUmSTCkubeoSVj2XJRKEngE2jOIFkoOOs3LJbBau2sfDNKnOHmKVPIOouxdYP384Db368HNwPFmie7VhdIvynM1pMC0UBS0RAUFQkpmWQlJiAnFxcaRkynUTIEaRQcStAHZ8v5C3e7XGxd4SiXlnfr4TJ7pXl6iRyvWjOIKoXPp45tJI0x6wY9Vcxox8l7eHT2dXUJJOAvfKQk+xdOJoxs1awcYfVzC4nRdmll3ZcC9eJIhnrmXtKxQJQnvsnoucKmUmwUc3MrCFE2aOfdh6L7HQAxwf8AfLF85j9uzZT0nzWHdUHSEqZ/6gkiYScu8h0UmZSB+dY+7g5lhYdxMJwsB6jUgQBqYw3YsrEB6wi8EtHLHtPI/A2PRC9ocHWz6kqbcnLi4uJSdXD974+gyJmUUNDMrwAOYNEQlC97rTf4kiQegf48pdgyDj+t8r6ezhQIvJO4h+4mSxrOjbXDh3ljNnzpSczvoTqA40oyEAjEgQlbsLlCSdSBAlofMi/KZI5djaMdSt6sWoXwNIyZ0i5Dc9+8zUnHNW1WetlpTUofA0/YkEoQkVw7gmEoRh6ElvUirTYvh18ss4uHThO7+iAVwyw65y/Ohh/v7776ekw5y/k4BcQ7wZkSD0pj69FywShN4hrtwVZMQHZweRdWw7in+DYwrZH9SSP/AdT0MvVxwdHUtONVx4bYUfCaINonIrvIzSiQRRRsCet9uTHu5jSH1HGg9bzvWITKRJkcSlPD6MKOXmEX79eS0//PBDyenHtey5EK7xeENF6DlmD2qKudXL/HQ7TnSUMqBOJBKEASlLH6LG3/2VXm7VaTZ0IUeO/cWqWZPZ8M9dMvKsjYIKhUJRqlT4KDkl6YkxPLx7k+O+X9CniRPGJm68u/J/nL9xl7CYJGR5deijYWKZOkFAJAidwGi4haTHXGDaK57YO9TA66UOjP9qD7dj08t/mJAyHN9pb9CsQR3cajpgYSKhShUjrByc8ajjTau3FnP9YSnC8hsutM+F5CJBPBdq1L4RgkpBzP3L/L3vT/yDIkhTnzateTGijJWokGWmk5qSQoqGlJqeaRCH15ax0c/d7SJBPHcqLXuDBEGFUqnEUE8aK3uLxRylRUAkiNIiJd4nIvACIiASxAuodLHJIgKlRUAkiNIiJd4nIvACIiASxAuodLHJIgKlRUAkiNIiJd4nIvACIvD/5XQq9GkO9DMAAAAASUVORK5CYII=)
"""

# Illustrate the effect of the tuning parameter on the cross validation error by  generating a plot
sns.set_theme()
sns.set_style("darkgrid", {"grid.color": ".5","image.cmap": "mako", "grid.linestyle": ":" })
plt.figure()
plt.figure(figsize=(16, 10), dpi=70)
plt.title('Deviverable 2: Effect of tuning parameter on the Cross Validation Error')
plt.xlabel('Œª Tuning Params')
plt.ylabel('CV Error')
sns.lineplot(x=Œª_log, y=CV , color='purple', markersize=12)
plt.savefig('SPritchard_CAP5625_Assignment1_Deliverable2.jpg')
plt.show()

"""## **Deliverable 3**

- Indicate the value of ùúÜ that generated the smallest CV(5) error
"""

#Find minimum MSE error
err = min(MSE)
# index MSE error 
i = MSE.index(err)
# Itereate to find MSe from Œª list
l = Œª[i]
# Output final results of lowest Œª tuning param
print("Best CV error of Œª = {e}\nBest tuning param of Œª = {l}".format(e=err, l=l))

"""## **Deliverable 4**
- Given the optimal ùúÜ, retrain your model on the entire dataset of ùëÅ = 400
observations and provide the estimates of the ùëù = 9 best-fit model parameters.
"""

# Retrain model based on Œª = 10.0
ùõΩx, _dh = RidgeRegression_BGD(X_p, Y_p, Œ±, l)
# Output best fit model params of  ùõΩx based on on Œª = 10.0 tuning param
print('Best fit model parameters', '\n', ùõΩx)